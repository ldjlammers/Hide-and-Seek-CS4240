{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BlogPost.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNn9HdciqflmLa0wyxKiavR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ldjlammers/Hide-and-Seek-CS4240/blob/master/BlogPost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vsvG125OuiR",
        "colab_type": "text"
      },
      "source": [
        "![alt text](./in-text-images/HideandSeekVisual.jpg)\n",
        "\n",
        "# The Hide and Seek method for classifaction and localisation\n",
        "\n",
        "*By: Laurens Lammers and Mink van Oosterhout*\n",
        "\n",
        "## 1. Introduction\n",
        "\n",
        "In this blog post we try to reproduce a method called \"Hide and Seek\", proposed by Singh and Lee in their 2017 paper '[Hide-and-Seek](https://arxiv.org/abs/1704.04232): Forcing a network to be Meticulous for weakly-supervised Object and Action Localization'. In particular we focus on object localization in images.\n",
        "\n",
        "This blog post is ...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYE7wWHtXl5z",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "## 2. What is Hide and Seek?\n",
        "\n",
        "'Hide and Seek' is a weakly-supervised framework that intents to improve object localization in images and action localization in videos. Instead of making algoritmic changes, or relying on external data, the Hide and Seek method makes changes to the input image. The key idea is to hide patches of the training images rondomly, forcing the network to seek other relevant parts when the most discriminative part is hidden. This principle is visualised in the image above at the top of the blog. The advantage of such an approach is that it can be applied to any network which is designed for object localisation. \n",
        "\n",
        "Most weakly-supervised localization methods identify discriminative patterns in the training data. These disciminative patterns are usually areas which occor frequently in one class and hardly ever in other classes. Due to variations within classes and leaning to much on just classification, these approaches frequently do not succeed in identifying the whole extent of an object. Instead, they only localize the most discriminative part of the object. Two examples of this can be seen in the image below. Because the head of the rabbit and the cilinder of the revolver distinguish them the most relative to other classes, the classiefer (over)focusses on these regions.\n",
        "\n",
        "![alt text](./in-text-images/discriminativeparts.jpg)\n",
        "\n",
        "To adress this problem, [Zhou et al.](https://arxiv.org/pdf/1512.04150.pdf) (2016) replaced max pooling after the final convolutional layer in a classification network with global average pooling. In this configuration, a very small maximum can no longer dictate the activation of an entire feature maps. Instead, it forces the network to look beyond the most discriminative parts, in order to achieve activation for a certain feature map. However, this approach did not solve the problem entirely. The network can still avoid learing less discriminative parts by finding more than one high-discriminative ones\n",
        "\n",
        "Blah blah"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXcWMGrnZ4A0",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "## 3. Approach"
      ]
    }
  ]
}